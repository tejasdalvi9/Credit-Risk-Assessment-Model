{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "379337ef",
   "metadata": {},
   "source": [
    "# Credit Risk Assessment Using PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef712e46",
   "metadata": {},
   "source": [
    "# Modelling   Stage II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9df36cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrypoint 2.x\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"CreditRiskModeling\").enableHiveSupport().getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7eb88bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac0bfcd",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ca68a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SeriousDlqin2yrs: integer (nullable = true)\n",
      " |-- RevolvingUtilizationOfUnsecuredLines: double (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- NumberOfTime30-59DaysPastDueNotWorse: integer (nullable = true)\n",
      " |-- DebtRatio: double (nullable = true)\n",
      " |-- MonthlyIncome: double (nullable = true)\n",
      " |-- NumberOfOpenCreditLinesAndLoans: integer (nullable = true)\n",
      " |-- NumberOfTimes90DaysLate: integer (nullable = true)\n",
      " |-- NumberRealEstateLoansOrLines: integer (nullable = true)\n",
      " |-- NumberOfTime60-89DaysPastDueNotWorse: integer (nullable = true)\n",
      " |-- NumberOfDependents: integer (nullable = true)\n",
      " |-- DebtRatioCategory: string (nullable = true)\n",
      "\n",
      "+----------------+------------------------------------+---+------------------------------------+-----------+\n",
      "|SeriousDlqin2yrs|RevolvingUtilizationOfUnsecuredLines|age|NumberOfTime30-59DaysPastDueNotWorse|  DebtRatio|\n",
      "+----------------+------------------------------------+---+------------------------------------+-----------+\n",
      "|               1|                         0.766126609| 45|                                   2|0.802982129|\n",
      "|               0|                         0.957151019| 40|                                   0|0.121876201|\n",
      "|               0|                          0.65818014| 38|                                   1|0.085113375|\n",
      "|               0|                         0.233809776| 30|                                   0|0.036049682|\n",
      "|               0|                           0.9072394| 49|                                   1|0.024925695|\n",
      "+----------------+------------------------------------+---+------------------------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------------+-------------------------------+-----------------------+----------------------------+\n",
      "|MonthlyIncome|NumberOfOpenCreditLinesAndLoans|NumberOfTimes90DaysLate|NumberRealEstateLoansOrLines|\n",
      "+-------------+-------------------------------+-----------------------+----------------------------+\n",
      "|       9120.0|                             13|                      0|                           6|\n",
      "|       2600.0|                              4|                      0|                           0|\n",
      "|       3042.0|                              2|                      1|                           0|\n",
      "|       3300.0|                              5|                      0|                           0|\n",
      "|      11037.5|                              7|                      0|                           1|\n",
      "+-------------+-------------------------------+-----------------------+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------------------------------------+------------------+-----------------+\n",
      "|NumberOfTime60-89DaysPastDueNotWorse|NumberOfDependents|DebtRatioCategory|\n",
      "+------------------------------------+------------------+-----------------+\n",
      "|                                   0|                 2|             High|\n",
      "|                                   0|                 1|              Low|\n",
      "|                                   0|                 0|              Low|\n",
      "|                                   0|                 0|              Low|\n",
      "|                                   0|                 0|              Low|\n",
      "+------------------------------------+------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "file_path = \"hdfs:///user/talentum/processed_data/cleaned_data_scalled/*.csv\"\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Display the schema and some initial data\n",
    "df.printSchema()\n",
    "df.select(df.columns[0:5]).show(5)\n",
    "df.select(df.columns[5:9]).show(5)\n",
    "df.select(df.columns[9:13]).show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26f1139",
   "metadata": {},
   "source": [
    "## One-Hot Encoding and Feature Assembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79b036e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# One-Hot Encoding for debtratiocategory\n",
    "indexer = StringIndexer(inputCol=\"DebtRatioCategory\", outputCol=\"debtratiocategory_index\")\n",
    "encoder = OneHotEncoder(inputCol=\"debtratiocategory_index\", outputCol=\"debtratiocategory_vec\")\n",
    "\n",
    "# Assemble features\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[col for col in df.columns if col != \"SeriousDlqin2yrs\" and col != \"DebtRatioCategory\"],\n",
    "    outputCol=\"features\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e907c1",
   "metadata": {},
   "source": [
    "##  Split Data into Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6228d316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b90da8",
   "metadata": {},
   "source": [
    "## Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df5f2d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the models\n",
    "log_reg = LogisticRegression(labelCol=\"SeriousDlqin2yrs\", featuresCol=\"features\")\n",
    "rf = RandomForestClassifier(labelCol=\"SeriousDlqin2yrs\", featuresCol=\"features\")\n",
    "gbt = GBTClassifier(labelCol=\"SeriousDlqin2yrs\", featuresCol=\"features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e99c18e",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning and Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c10d23ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyperparameter tuning using cross-validation\n",
    "param_grid_lr = (ParamGridBuilder()\n",
    "                 .addGrid(log_reg.regParam, [0.01, 0.1 ])\n",
    "                 .addGrid(log_reg.elasticNetParam, [0.0, 0.5])\n",
    "                 .build())\n",
    "\n",
    "param_grid_rf = (ParamGridBuilder()\n",
    "                 .addGrid(rf.numTrees, [100, 200])\n",
    "                 .addGrid(rf.maxDepth, [5, 10])\n",
    "                 .build())\n",
    "\n",
    "param_grid_gbt = (ParamGridBuilder()\n",
    "                  .addGrid(gbt.maxDepth, [5, 10])\n",
    "                  .addGrid(gbt.maxIter, [5, 10])\n",
    "                  .build())\n",
    "\n",
    "\n",
    "# Define the evaluator\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"SeriousDlqin2yrs\")\n",
    "\n",
    "# Define the cross-validators\n",
    "cv_lr = CrossValidator(estimator=log_reg, estimatorParamMaps=param_grid_lr, evaluator=evaluator, numFolds=2)\n",
    "cv_rf = CrossValidator(estimator=rf, estimatorParamMaps=param_grid_rf, evaluator=evaluator, numFolds=2)\n",
    "cv_gbt = CrossValidator(estimator=gbt, estimatorParamMaps=param_grid_gbt, evaluator=evaluator, numFolds=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2036ad87",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13fb796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create pipeline\n",
    "pipeline_lr = Pipeline(stages=[indexer, encoder, assembler, cv_lr])\n",
    "pipeline_rf = Pipeline(stages=[indexer, encoder, assembler, cv_rf])\n",
    "pipeline_gbt = Pipeline(stages=[indexer, encoder, assembler, cv_gbt])\n",
    "\n",
    "# Train the models on the training set\n",
    "model_lr = pipeline_lr.fit(train_df)\n",
    "model_rf = pipeline_rf.fit(train_df)\n",
    "model_gbt = pipeline_gbt.fit(train_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02d8b18",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7214fb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for Logistic Regression: 0.8543626111531084\n",
      "AUC for Random Forest: 0.8444228318392916\n",
      "AUC for Gradient Boosted Decision Tree: 0.8550442272383626\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the models on the test set\n",
    "auc_lr = evaluator.evaluate(model_lr.transform(test_df))\n",
    "auc_rf = evaluator.evaluate(model_rf.transform(test_df))\n",
    "auc_gbt = evaluator.evaluate(model_gbt.transform(test_df))\n",
    "\n",
    "# Print the results\n",
    "print(f\"AUC for Logistic Regression: {auc_lr}\")\n",
    "print(f\"AUC for Random Forest: {auc_rf}\")\n",
    "print(f\"AUC for Gradient Boosted Decision Tree: {auc_gbt}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bbb33b",
   "metadata": {},
   "source": [
    "## Best Model and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8698025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression: {'elasticNetParam': 0.0, 'regParam': 0.01}\n",
      "Best parameters for Random Forest: {'maxDepth': 5, 'numTrees': 100}\n",
      "Best parameters for Gradient Boosted Decision Tree: {'maxDepth': 5, 'maxIter': 5}\n"
     ]
    }
   ],
   "source": [
    "# Function to filter parameters based on the parameter grid\n",
    "def filter_best_params(best_model, param_grid):\n",
    "    param_names = [param.name for param in param_grid]\n",
    "    best_params = {}\n",
    "    for param in best_model.extractParamMap():\n",
    "        if param.name in param_names:\n",
    "            best_params[param.name] = best_model.extractParamMap()[param]\n",
    "    return best_params\n",
    "\n",
    "\n",
    "# Find the best model and its parameters\n",
    "best_model_lr = model_lr.stages[-1].bestModel\n",
    "best_model_rf = model_rf.stages[-1].bestModel\n",
    "best_model_gbt = model_gbt.stages[-1].bestModel\n",
    "\n",
    "# Extracting the relevant best parameters based on the param grid\n",
    "best_params_lr = filter_best_params(best_model_lr, [log_reg.regParam, log_reg.elasticNetParam])\n",
    "best_params_rf = filter_best_params(best_model_rf, [rf.numTrees, rf.maxDepth])\n",
    "best_params_gbt = filter_best_params(best_model_gbt, [gbt.maxDepth, gbt.maxIter])\n",
    "\n",
    "# Print the best parameters for each model\n",
    "print(\"Best parameters for Logistic Regression:\", best_params_lr)\n",
    "print(\"Best parameters for Random Forest:\", best_params_rf)\n",
    "print(\"Best parameters for Gradient Boosted Decision Tree:\", best_params_gbt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544bbe02",
   "metadata": {},
   "source": [
    "## Saving the best model by Training it with best parameters by creating Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5783c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-create the GBTClassifier with the best parameters\n",
    "gbt_best = GBTClassifier(labelCol=\"SeriousDlqin2yrs\", featuresCol=\"features\", maxDepth=5, maxIter=5)\n",
    "\n",
    "# Create a pipeline with the re-created GBT model\n",
    "pipeline_best_gbt = Pipeline(stages=[indexer, encoder, assembler, gbt_best])\n",
    "\n",
    "# Retrain the model on the entire training dataset\n",
    "best_model_gbt = pipeline_best_gbt.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9dce70f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best models saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define the path to save the retrained GBT model\n",
    "path_best_gbt = \"hdfs:///user/talentum/models/\"\n",
    "\n",
    "import subprocess\n",
    "# Define the HDFS command\n",
    "command = \"hdfs dfs -rm -r models\"\n",
    "# Run the command\n",
    "subprocess.run(command, shell=True, check=True)\n",
    "\n",
    "# Save the retrained model\n",
    "best_model_gbt.save(path_best_gbt)\n",
    "\n",
    "print(\"Best models saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
